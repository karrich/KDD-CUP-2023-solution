{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63e0e1d4-ac95-4000-a019-d9968b8775b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from torch.optim import *\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from typing import Optional, Callable, Any, Tuple\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM,BertModel,get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import classification_report, precision_score, mean_squared_error\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import torch.nn.functional as F\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "def seed_everything(seed=2001):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.enabled = True\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "386bb882-5d90-47d3-837a-b32ea59efa8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_df = pd.read_csv(\"./data/products_train.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ee66643-7716-418f-bacb-b005f5137a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"xlm-roberta-base\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9cd144b-b780-4d50-bfaf-b475abbabf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = np.array(data)\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.data[idx]\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "374abe51-db61-4ba7-ba39-1f547a0cd442",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    max_length = max([len(x) for x in data])\n",
    "    max_length = min(512,max_length)\n",
    "    attention_mask,input_ids,weight =[], [], []\n",
    "    for x in data:\n",
    "        if len(x)>max_length:\n",
    "            x = x[:max_length//2] + x[len(x)-max_length//2:]\n",
    "        attention = [1] * len(x) + [0] * (max_length - len(x))\n",
    "        attention_mask.append(attention)\n",
    "        if len(x) == 2:\n",
    "            weight.append(0)\n",
    "        else:\n",
    "            weight.append(1)\n",
    "        x = x + [0] * (max_length - len(x))\n",
    "        input_ids.append(x)\n",
    "        \n",
    "    input_ids = torch.tensor(input_ids)\n",
    "    attention_mask = torch.tensor(attention_mask)\n",
    "    weight = torch.tensor(weight).unsqueeze(1)\n",
    "\n",
    "    return input_ids, attention_mask, weight"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bc89abb8-b8dc-4da4-8344-30ab566352f1",
   "metadata": {},
   "source": [
    "# bert whitening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44cb7469-0fd1-4f93-a0ab-38992a09f050",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_kernel_bias(vecs, vec_dim):\n",
    "\n",
    "    mu = vecs.mean(axis=0, keepdims=True)\n",
    "    cov = np.cov(vecs.T)\n",
    "    u, s, vh = np.linalg.svd(cov)\n",
    "    W = np.dot(u, np.diag(1 / np.sqrt(s)))\n",
    "\n",
    "    return W[:, :vec_dim], -mu\n",
    "def transform_and_normalize(vecs, kernel=None, bias=None):\n",
    "    if not (kernel is None or bias is None):\n",
    "        vecs = (vecs + bias).dot(kernel)\n",
    "    return vecs / (vecs**2).sum(axis=1, keepdims=True)**0.5\n",
    "def white(vecs,dim=256):\n",
    "    kernel, bias = compute_kernel_bias(vecs, dim)\n",
    "    vecs = transform_and_normalize(vecs, kernel, bias)\n",
    "    return vecs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cf0f67f1-30f1-4926-9e4d-dc791a6e09fd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# title process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c910effd-8d4c-40d3-863b-88ce8908e27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = np.array(pro_df['title'].tolist())\n",
    "for k in range(len(title)):\n",
    "    text = title[k]\n",
    "    for i in '@#$%^&*()_+-=~`?><:;}{[]\\|\"':\n",
    "        text = text.replace(i, ' ')\n",
    "    title[k] = text\n",
    "    if title[k].isdigit() or (title[k].isalpha() and len(title[k])<3) or title[k] == 'nan':\n",
    "        title[k] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28ad80d4-873a-449f-a7ac-051bf41a4de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1551057/1551057 [05:08<00:00, 5025.05it/s]\n"
     ]
    }
   ],
   "source": [
    "title_ids = []\n",
    "for item in tqdm(title):\n",
    "    title_ids.append(tokenizer(item).input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de5a6101-5d99-4220-aeda-81386281446e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sjliu/anaconda3/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "np.save('./title_ids',np.array(title_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8eabcda-ef22-4534-8db7-d519da8a0c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_ids = np.load('./title_ids.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d83a13e9-062e-4f93-b11f-dab3d6cd8301",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = MyDataset(title_ids)\n",
    "dataloader = DataLoader(data_set, batch_size=128, collate_fn=collate_fn, shuffle=False, pin_memory=True,\n",
    "                              num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "746f7ca4-56f5-4e33-b7aa-aa0df954a756",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12118/12118 [1:04:56<00:00,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1551057, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "title_embeddings = torch.tensor([])\n",
    "for input_ids, attention_mask, weight in tqdm(dataloader):\n",
    "    with torch.no_grad():\n",
    "        with autocast():\n",
    "            embeddings = model.roberta(input_ids = input_ids.to(device),\n",
    "                                       attention_mask=attention_mask.to(device)\n",
    "                                      ).last_hidden_state[:,0,:].cpu()* weight\n",
    "    title_embeddings = torch.cat([title_embeddings,embeddings],dim=0)\n",
    "print(title_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8772db1-5a02-43b7-b79f-98b32304293b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim=128\n",
    "title_embeddings = torch.load('./title_embeddings_768.dataset').cpu().numpy()\n",
    "title_embeddings = torch.tensor(white(title_embeddings,dim),dtype=torch.float32).cpu()\n",
    "torch.save(title_embeddings,'./title_embeddings_'+str(dim)+'.dataset')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
