{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce79e081-30bf-46b4-ac4c-0424b4651a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f20d39bd-a1fd-4c7c-92d6-dca63d4b1ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn import datasets\n",
    "cudf.set_option(\"default_integer_bitwidth\", 32)\n",
    "cudf.set_option(\"default_float_bitwidth\", 32)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "767151bc-8abf-4587-ab4e-cf9849c055f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "            'user_user_count',\n",
    "            'user_item_count',\n",
    "            'remember_ratio',\n",
    "            'price',\n",
    "            'price_power_0_mean',\n",
    "            'price_power_1_mean',\n",
    "            'price_power_2_mean',\n",
    "            'price_power_3_mean',\n",
    "            'price_power_5_mean',\n",
    "            'nn_logits',\n",
    "            'es',\n",
    "            'fr',\n",
    "            'it',\n",
    "           ]\n",
    "bad = [4,7,#1\n",
    "       11,14,#2\n",
    "       18,21,#3\n",
    "       25,28,#4\n",
    "       32,35,#5\n",
    "       39,42,#6\n",
    "       44,45,46,47,48,49,#7\n",
    "       60,62,63,#9\n",
    "       66,67,70,#10\n",
    "       72,73,74,75,76,77,#11\n",
    "       80,81,84,#12\n",
    "       87,88,89,90,91,#13\n",
    "       101,102,103,104,105,#15\n",
    "       108,109,110,111,112,#16\n",
    "       115,116,117,118,119,#17\n",
    "       123,126,#18\n",
    "       130,133,#19\n",
    "       144,147,#21\n",
    "       151,154,#22\n",
    "       158,151,#23\n",
    "       203,206,\n",
    "       ]#DE\n",
    "bad = [\n",
    "       72,73,74,75,76,77,#11 string\n",
    "       101,102,103,104,105,#15 brand\n",
    "       108,109,110,111,112,#16 author\n",
    "       115,116,117,118,119,#17 material\n",
    "       182,189,196,30*7,\n",
    "       ]#DE\n",
    "feature_list =  [[200,206]]\n",
    "for i in [1,2,3,4,5,6,7,9,10,11,12,13,15,16,17,18,19,21,23,24,25,26,27,28,31]:\n",
    "    feature_list.append([(i-1)*7+1,i*7])\n",
    "for i in feature_list:\n",
    "    for j in range(i[0],i[1]+1):\n",
    "        if j in bad:\n",
    "            continue\n",
    "        features+=['ui_feat'+str(j)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cafde789-3f90-4518-8c55-f3616b1871a8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 11/26 [00:00<00:00, 53.54it/s]/tmp/ipykernel_1996899/3509222865.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  valid['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/3509222865.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  valid['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/3509222865.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  valid['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/3509222865.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  valid['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      " 65%|██████▌   | 17/26 [00:00<00:00, 52.72it/s]/tmp/ipykernel_1996899/3509222865.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  valid['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/3509222865.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  valid['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/3509222865.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  valid['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/3509222865.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  valid['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/3509222865.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  valid['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/3509222865.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  valid['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/3509222865.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  valid['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/3509222865.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  valid['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/3509222865.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  valid['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/3509222865.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  valid['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/3509222865.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  valid['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/3509222865.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  valid['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/3509222865.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  valid['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/3509222865.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  valid['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/3509222865.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  valid['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/3509222865.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  valid['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/3509222865.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  valid['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/3509222865.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  valid['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/3509222865.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  valid['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/3509222865.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  valid['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/3509222865.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  valid['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/3509222865.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  valid['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/3509222865.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  valid['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/3509222865.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  valid['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/3509222865.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  valid['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/3509222865.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  valid['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/3509222865.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  valid['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/3509222865.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  valid['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/3509222865.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  valid['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/3509222865.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  valid['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/3509222865.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  valid['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/3509222865.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  valid['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/3509222865.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  valid['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/3509222865.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  valid['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/3509222865.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  valid['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/3509222865.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  valid['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/3509222865.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  valid['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/3509222865.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  valid['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/3509222865.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  valid['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/3509222865.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  valid['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/3509222865.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  valid['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      " 88%|████████▊ | 23/26 [00:00<00:00, 52.38it/s]/tmp/ipykernel_1996899/3509222865.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  valid['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/3509222865.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  valid['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/3509222865.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  valid['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/3509222865.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  valid['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/3509222865.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  valid['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/3509222865.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  valid['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/3509222865.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  valid['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/3509222865.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  valid['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/3509222865.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  valid['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/3509222865.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  valid['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/3509222865.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  valid['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/3509222865.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  valid['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/3509222865.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  valid['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/3509222865.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  valid['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/3509222865.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  valid['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/3509222865.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  valid['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/3509222865.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  valid['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/3509222865.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  valid['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/3509222865.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  valid['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "100%|██████████| 26/26 [00:00<00:00, 52.22it/s]\n"
     ]
    }
   ],
   "source": [
    "valid = []\n",
    "data_set = ['FR']\n",
    "for locale__2 in data_set :#['ES','FR','IT']\n",
    "    temp_valid = pd.read_parquet('valid5_data_'+locale__2+'_0~0.pqt')\n",
    "    a = [0]*len(temp_valid)\n",
    "    b = [0]*len(temp_valid)\n",
    "    c = [0]*len(temp_valid)\n",
    "    if locale__2 == 'ES':\n",
    "        a = [1]*len(temp_valid)\n",
    "    if locale__2 == 'FR':\n",
    "        b = [1]*len(temp_valid)\n",
    "    if locale__2 == 'IT':\n",
    "        c = [1]*len(temp_valid)\n",
    "    temp_valid['es']=a\n",
    "    temp_valid['fr']=b\n",
    "    temp_valid['it']=c\n",
    "    valid.append(temp_valid)\n",
    "    \n",
    "valid = pd.concat(valid).reset_index(drop=True)\n",
    "for row in tqdm(feature_list):\n",
    "    temp_df = []\n",
    "    for locale__2 in data_set :#['ES','FR','IT']\n",
    "        temp_df.append(pd.read_parquet('valid5_data_'+locale__2+'_'+str(row[0])+'~'+str(row[1])+'.pqt'))\n",
    "    temp_df = pd.concat(temp_df).reset_index(drop=True)\n",
    "    \n",
    "    for j in range(row[0],row[1]+1):\n",
    "        if j in bad:\n",
    "            continue\n",
    "        valid['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
    "    del temp_df\n",
    "X_valid = valid[features]\n",
    "y_valid = valid['target']\n",
    "dvalid = xgb.DMatrix(cudf.DataFrame(X_valid),cudf.DataFrame( y_valid), group=[250] * (len(X_valid)//250) ) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e507d521-47e1-49ad-9f33-8cacc5a371ae",
   "metadata": {
    "tags": []
   },
   "source": [
    "# GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43966f3e-e7b4-46e4-b488-a9cf5ff506ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IterLoadForDMatrix(xgb.core.DataIter):\n",
    "    def __init__(self, df=None, features=None, batch_size=1024*256):\n",
    "        self.features = features\n",
    "        self.target = 'target'\n",
    "        self.df = df\n",
    "        self.it = 0 # set iterator to 0\n",
    "        self.batch_size = batch_size\n",
    "        self.batches = int( np.ceil( len(df) / self.batch_size ) )\n",
    "        super().__init__()\n",
    "\n",
    "    def reset(self):\n",
    "        '''Reset the iterator'''\n",
    "        self.it = 0\n",
    "\n",
    "    def next(self, input_data):\n",
    "        '''Yield next batch of data.'''\n",
    "        if self.it == self.batches:\n",
    "            return 0 # Return 0 when there's no more batch.\n",
    "        \n",
    "        a = self.it * self.batch_size\n",
    "        b = min( (self.it + 1) * self.batch_size, len(self.df) )\n",
    "        dt = cudf.DataFrame(self.df.iloc[a:b])\n",
    "        input_data(data=dt[self.features], label=dt[self.target]) #, weight=dt['weight'])\n",
    "        self.it += 1\n",
    "        return 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "de484f54-409c-4eb3-b9d0-7c9b3955b0b0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# mrr100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fd92409-ea0d-46e9-8977-bdd9ad16715b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Tuple\n",
    "def mrr_at_k(predt: np.ndarray, dtrain: xgb.DMatrix, k: int) -> Tuple[str, float]:\n",
    "    y = dtrain.get_label()\n",
    "    group_sizes = dtrain.get_group()\n",
    "    assert len(y) == sum(group_sizes), \"group sizes must match data length\"\n",
    "    assert len(predt) == sum(group_sizes), \"group sizes must match prediction length\"\n",
    "    mrr_sum = 0.\n",
    "    mrr_count = 0\n",
    "    start_idx = 0\n",
    "    for i, group_size in enumerate(group_sizes):\n",
    "        end_idx = start_idx + group_size\n",
    "        group_y = y[start_idx:end_idx]\n",
    "        group_predt = predt[start_idx:end_idx]\n",
    "        order = np.argsort(-group_predt)\n",
    "        ranks = np.zeros_like(order)\n",
    "        ranks[order] = np.arange(len(group_predt))\n",
    "        reciprocal_ranks = 1. / (ranks + 1.)\n",
    "        if (group_y > 0).sum() == 0:\n",
    "            mrr = 0.\n",
    "        else:\n",
    "            mrr = np.mean(reciprocal_ranks[group_y > 0])\n",
    "        mrr_sum += mrr\n",
    "        mrr_count += 1\n",
    "        start_idx = end_idx\n",
    "    mrr_at_k = mrr_sum / mrr_count if mrr_count > 0 else 0.\n",
    "    return f\"mrr@{k}\", mrr_at_k"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "17bedf98-c20b-43e9-a1df-064d5b6d7dda",
   "metadata": {
    "tags": []
   },
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "befeaf72-0ee2-45d6-a280-169bf33ec153",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 16/26 [02:36<02:12, 13.28s/it]/tmp/ipykernel_1996899/4049417552.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/4049417552.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/4049417552.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/4049417552.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      " 65%|██████▌   | 17/26 [02:52<02:08, 14.22s/it]/tmp/ipykernel_1996899/4049417552.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/4049417552.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/4049417552.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/4049417552.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/4049417552.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/4049417552.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/4049417552.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      " 69%|██████▉   | 18/26 [03:04<01:48, 13.56s/it]/tmp/ipykernel_1996899/4049417552.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/4049417552.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/4049417552.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/4049417552.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/4049417552.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/4049417552.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/4049417552.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      " 73%|███████▎  | 19/26 [03:16<01:31, 13.09s/it]/tmp/ipykernel_1996899/4049417552.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/4049417552.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/4049417552.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/4049417552.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/4049417552.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/4049417552.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/4049417552.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      " 77%|███████▋  | 20/26 [03:33<01:25, 14.25s/it]/tmp/ipykernel_1996899/4049417552.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/4049417552.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/4049417552.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/4049417552.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/4049417552.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/4049417552.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/4049417552.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      " 81%|████████  | 21/26 [03:49<01:12, 14.52s/it]/tmp/ipykernel_1996899/4049417552.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/4049417552.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/4049417552.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/4049417552.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/4049417552.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/4049417552.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/4049417552.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      " 85%|████████▍ | 22/26 [04:02<00:56, 14.22s/it]/tmp/ipykernel_1996899/4049417552.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/4049417552.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/4049417552.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/4049417552.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/4049417552.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/4049417552.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      " 88%|████████▊ | 23/26 [04:14<00:40, 13.59s/it]/tmp/ipykernel_1996899/4049417552.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/4049417552.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/4049417552.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/4049417552.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/4049417552.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/4049417552.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      " 92%|█████████▏| 24/26 [04:26<00:25, 12.97s/it]/tmp/ipykernel_1996899/4049417552.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/4049417552.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/4049417552.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/4049417552.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/4049417552.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/4049417552.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      " 96%|█████████▌| 25/26 [04:42<00:14, 14.04s/it]/tmp/ipykernel_1996899/4049417552.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/4049417552.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/4049417552.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/4049417552.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/4049417552.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/4049417552.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "/tmp/ipykernel_1996899/4049417552.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
      "100%|██████████| 26/26 [04:56<00:00, 11.41s/it]\n",
      "/home/sjliu/anaconda3/envs/rapids-23.02/lib/python3.10/site-packages/xgboost/core.py:1461: FutureWarning: Please use `QuantileDMatrix` instead.\n",
      "  warnings.warn(\"Please use `QuantileDMatrix` instead.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "train = []\n",
    "data_set = ['ES','FR','IT']\n",
    "for locale__2 in data_set :#['DE','JP','UK']\n",
    "    temp_train = pd.read_parquet('train5_data_'+locale__2+'_0~0.pqt')\n",
    "    a = [0]*len(temp_train)\n",
    "    b = [0]*len(temp_train)\n",
    "    c = [0]*len(temp_train)\n",
    "    if locale__2 == 'ES':\n",
    "        a = [1]*len(temp_train)\n",
    "    if locale__2 == 'FR':\n",
    "        b = [1]*len(temp_train)\n",
    "    if locale__2 == 'IT':\n",
    "        c = [1]*len(temp_train)\n",
    "    temp_train['es']=a\n",
    "    temp_train['fr']=b\n",
    "    temp_train['it']=c\n",
    "    train.append(temp_train)\n",
    "    \n",
    "train = pd.concat(train).reset_index(drop=True)\n",
    "for row in tqdm(feature_list):\n",
    "    temp_df = []\n",
    "    for locale__2 in data_set :#['DE','JP','UK']\n",
    "        temp_df.append(pd.read_parquet('train5_data_'+locale__2+'_'+str(row[0])+'~'+str(row[1])+'.pqt'))\n",
    "    temp_df = pd.concat(temp_df).reset_index(drop=True)\n",
    "    \n",
    "    for j in range(row[0],row[1]+1):\n",
    "        if j in bad:\n",
    "            continue\n",
    "        train['ui_feat'+str(j)] = temp_df['ui_feat'+str(j)]\n",
    "    del temp_df\n",
    "\n",
    "Xy_train = IterLoadForDMatrix(train, features)\n",
    "dtrain = xgb.DeviceQuantileDMatrix(Xy_train, max_bin=256)\n",
    "dtrain.set_group([250] * (len(train)//250))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5c93947-c7f4-4f99-b14d-c58c3d85bc51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.401391432584136"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = valid['target'].tolist()\n",
    "rank = valid['rank'].tolist()\n",
    "mrr = 0\n",
    "for i in range(len(rank)//250):\n",
    "    for j in range(100):\n",
    "        if target[i*250+j] == 1:\n",
    "            mrr+=1/(1+j)\n",
    "mrr/len(rank)*250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdd2400-a400-4276-aa69-dbeb1e8135c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xgb_parms = { \n",
    "        'max_depth':4, \n",
    "        'learning_rate':0.07, \n",
    "        'subsample':0.5,\n",
    "        'colsample_bytree':0.6,\n",
    "        # 'colsample_bylevel': 0.6,\n",
    "        # 'min_child_weight': 5,\n",
    "        # 'gamma':0.1,\n",
    "        'reg_lambda':0.05,\n",
    "        'eval_metric':'map',\n",
    "        'objective':'binary:logistic',\n",
    "        # 'objective':'rank:pairwise',\n",
    "        'scale_pos_weight':8,\n",
    "\n",
    "        'tree_method':'gpu_hist',\n",
    "        'predictor':'gpu_predictor',\n",
    "        'num_feature':len(features),\n",
    "        'random_state':42\n",
    "    }\n",
    "model = None\n",
    "_ = xgb.train(xgb_parms, \n",
    "    dtrain=dtrain,\n",
    "    evals=[(dtrain,'train'),(dvalid,'valid')],\n",
    "    feval=lambda predt, dtrain: mrr_at_k(predt, dtrain, k=100),\n",
    "    num_boost_round=1,\n",
    "    early_stopping_rounds=0,\n",
    "    verbose_eval=1,\n",
    "    xgb_model=model)\n",
    "model = xgb.train(xgb_parms, \n",
    "    dtrain=dtrain,\n",
    "    evals=[(dtrain,'train'),(dvalid,'valid')],\n",
    "    num_boost_round=3500,\n",
    "    early_stopping_rounds=300,\n",
    "    verbose_eval=100,\n",
    "    xgb_model=model)\n",
    "_ = xgb.train(xgb_parms, \n",
    "    dtrain=dtrain,\n",
    "    evals=[(dtrain,'train'),(dvalid,'valid')],\n",
    "    feval=lambda predt, dtrain: mrr_at_k(predt, dtrain, k=100),\n",
    "    num_boost_round=1,\n",
    "    early_stopping_rounds=0,\n",
    "    verbose_eval=1,\n",
    "    xgb_model=model)\n",
    "\n",
    "model.save_model(f'XGB_locale_sum4.xgb')\n",
    "#[0]\ttrain-map:0.61478\ttrain-mrr@100:0.45069\tvalid-map:0.60668\tvalid-mrr@100:0.46838"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fca7dd3a-ac38-488e-9cb3-118495037471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-map:0.61479\ttrain-mrr@100:0.45071\tvalid-map:0.60578\tvalid-mrr@100:0.46748\n"
     ]
    }
   ],
   "source": [
    "_ = xgb.train(  xgb_parms, \n",
    "                dtrain=dtrain,\n",
    "                evals=[(dtrain,'train'),(dvalid,'valid')],\n",
    "                feval=lambda predt, dtrain: mrr_at_k(predt, dtrain, k=100),\n",
    "                num_boost_round=1,\n",
    "                early_stopping_rounds=0,\n",
    "                verbose_eval=1,\n",
    "                xgb_model=model)#0.36880"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad8e47d-4e04-417a-ae1d-17a80544e8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.save_model(f'XGB_locale_sum4.xgb')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b850d254",
   "metadata": {},
   "source": [
    "### features importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0200157c-4e08-48b7-b4b7-98f158ea3b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = features#list(model.get_score(importance_type='gain').keys())\n",
    "b = list(model.get_score(importance_type='gain').values())\n",
    "Z = zip(b, a)  \n",
    "Z = sorted(Z, reverse=True)\n",
    "b, a = zip(*Z)\n",
    "for i,j in zip(b, a):\n",
    "    print(i,'\\t',j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13117710-ed3c-4d86-9c98-cecfa8d4bdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    " \n",
    "pid = os.getpid()\n",
    "!kill -9 $pid"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b515f087-536d-43f0-b248-31af49698612",
   "metadata": {
    "tags": []
   },
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f44a63a-e392-46a2-9f90-66bfb8c7460d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test\n",
    "xgb_parms = { \n",
    "            'max_depth':4, \n",
    "            'learning_rate':0.07, \n",
    "            'subsample':0.5,\n",
    "            'colsample_bytree':0.6,\n",
    "            # 'gamma':0.1,\n",
    "            'reg_lambda':0.05,\n",
    "            'eval_metric':'map',\n",
    "            'objective':'binary:logistic',\n",
    "            # 'objective':'rank:pairwise',\n",
    "            'scale_pos_weight':8,\n",
    "            'tree_method':'gpu_hist',\n",
    "            'predictor':'gpu_predictor',\n",
    "            'random_state':42\n",
    "        }\n",
    "model = xgb.Booster()\n",
    "# model.set_param(xgb_parms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc8b0e11-c54a-461a-82cf-b72259ec8c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:40<00:00, 13.35s/it]\n"
     ]
    }
   ],
   "source": [
    "recall1 = []\n",
    "le = 0\n",
    "\n",
    "for locale__ in tqdm(['ES','FR','IT']):\n",
    "    model = xgb.Booster()\n",
    "    model.load_model(f'XGB_locale_sum4.xgb')\n",
    "    data = cudf.read_parquet('test5_data_'+locale__+'_0~0.pqt')\n",
    "    a = [0]*len(data)\n",
    "    b = [0]*len(data)\n",
    "    c = [0]*len(data)\n",
    "    if locale__ == 'ES':\n",
    "        a = [1]*len(data)\n",
    "    if locale__ == 'FR':\n",
    "        b = [1]*len(data)\n",
    "    if locale__ == 'IT':\n",
    "        c = [1]*len(data)\n",
    "    data['es']=a\n",
    "    data['fr']=b\n",
    "    data['it']=c\n",
    "    if len(data)==0:\n",
    "        break\n",
    "    for row in feature_list:\n",
    "        temp_df = cudf.read_parquet('test5_data_'+locale__+'_'+str(row[0])+'~'+str(row[1])+'.pqt')\n",
    "        for j in range(row[0],row[1]+1):\n",
    "            if j in bad:\n",
    "                continue\n",
    "            data['ui_feat'+str(j)] = cudf.DataFrame(temp_df['ui_feat'+str(j)])\n",
    "    le+=len(data)\n",
    "\n",
    "    dtest = xgb.DMatrix(data=cudf.DataFrame(data[features]))\n",
    "    preds = model.predict(dtest)\n",
    "    preds = np.array(preds)*np.log(np.e+5*data['sum_pop_score'].to_pandas())\n",
    "    del dtest\n",
    "    predictions = cudf.DataFrame(data[['user', 'item']])\n",
    "    predictions['pred'] = preds\n",
    "    predictions = predictions.sort_values(['user', 'pred'], ascending=[True, False]).reset_index(drop=True)\n",
    "    predictions['rk'] = predictions.groupby('user').item.cumcount().astype('int16')\n",
    "    predictions = predictions.loc[predictions.rk < 150]\n",
    "    predictions = predictions.to_pandas()\n",
    "    predictions = predictions.groupby('user').item.apply(list).to_frame().reset_index()\n",
    "    predictions.columns = ['test_user', 'next_item_prediction']\n",
    "    recall1 += predictions['next_item_prediction'].tolist()\n",
    "    del predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "36358d70-63b8-41c7-874b-eb9222b8b241",
   "metadata": {
    "tags": []
   },
   "source": [
    "### outout result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "616db35a-3f07-4767-91e5-8fd0c1deb4fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>locale</th>\n",
       "      <th>next_item_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ES</td>\n",
       "      <td>[B074581R8Y, B074RZKWMD, B0745795KF, B07GTWD7Z...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ES</td>\n",
       "      <td>[B09J4T4JF5, B09NT33LZN, B09M8LNB61, B09NQKCQW...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ES</td>\n",
       "      <td>[B0B461V1RB, B0B4643ZJN, B0B461KYQY, B0B38J377...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ES</td>\n",
       "      <td>[B07R4VG9X3, B07R4WKSSV, B07QZ35DY6, B07QXZJK8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ES</td>\n",
       "      <td>[B09G97SLGS, B09G9DMQ7M, B09G99D95Q, B09G9LF91...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34685</th>\n",
       "      <td>IT</td>\n",
       "      <td>[B01F545TZQ, B01BBW9OAC, B09QH4W4LS, B01BBW9V3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34686</th>\n",
       "      <td>IT</td>\n",
       "      <td>[B08DYGN5W7, B09TW215N7, B08DJ18C85, B00IBDVTS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34687</th>\n",
       "      <td>IT</td>\n",
       "      <td>[B07ZH7HYDX, B07KXXCDS2, B00P2J6IP0, B08MNSMFP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34688</th>\n",
       "      <td>IT</td>\n",
       "      <td>[B09RBZ3XDV, B09T5N86FW, B09V52D3SQ, B0B245K5X...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34689</th>\n",
       "      <td>IT</td>\n",
       "      <td>[B08PCP2BB4, B08PCQQRB2, B08PCPF8G2, B09GYCC1N...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34690 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      locale                               next_item_prediction\n",
       "0         ES  [B074581R8Y, B074RZKWMD, B0745795KF, B07GTWD7Z...\n",
       "1         ES  [B09J4T4JF5, B09NT33LZN, B09M8LNB61, B09NQKCQW...\n",
       "2         ES  [B0B461V1RB, B0B4643ZJN, B0B461KYQY, B0B38J377...\n",
       "3         ES  [B07R4VG9X3, B07R4WKSSV, B07QZ35DY6, B07QXZJK8...\n",
       "4         ES  [B09G97SLGS, B09G9DMQ7M, B09G99D95Q, B09G9LF91...\n",
       "...      ...                                                ...\n",
       "34685     IT  [B01F545TZQ, B01BBW9OAC, B09QH4W4LS, B01BBW9V3...\n",
       "34686     IT  [B08DYGN5W7, B09TW215N7, B08DJ18C85, B00IBDVTS...\n",
       "34687     IT  [B07ZH7HYDX, B07KXXCDS2, B00P2J6IP0, B08MNSMFP...\n",
       "34688     IT  [B09RBZ3XDV, B09T5N86FW, B09V52D3SQ, B0B245K5X...\n",
       "34689     IT  [B08PCP2BB4, B08PCQQRB2, B08PCPF8G2, B09GYCC1N...\n",
       "\n",
       "[34690 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "product_id2asin = pickle.load(open('../data/product_id2asin.pkl', 'rb'))\n",
    "locale = pd.read_pickle('../data/test_data2_p2.dataset').reset_index(drop=True)['locale']\n",
    "result = [[product_id2asin[x] for x in row[:100]] for row in recall1]\n",
    "result = pd.DataFrame({'locale':locale,'next_item_prediction':result})\n",
    "result.to_parquet( 'submission_locale_sum.parquet', engine='pyarrow')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5a3f12b3-cdc6-4ed8-ad41-12bd34f996f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>locale</th>\n",
       "      <th>next_item_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ES</td>\n",
       "      <td>[B074581R8Y, B074RZKWMD, B0745795KF, B07457KX2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ES</td>\n",
       "      <td>[B09J4T4JF5, B09NT33LZN, B09M8LNB61, B09NQKCQW...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ES</td>\n",
       "      <td>[B0B461V1RB, B0B4643ZJN, B0B461KYQY, B0B38J377...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ES</td>\n",
       "      <td>[B07R4VG9X3, B07R4WKSSV, B07QZ35DY6, B07QXZJK8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ES</td>\n",
       "      <td>[B09G97SLGS, B09G9DMQ7M, B09G99D95Q, B09G9LF91...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34685</th>\n",
       "      <td>IT</td>\n",
       "      <td>[B01F545TZQ, B01BBW9OAC, B09QH4W4LS, B01BBW9V3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34686</th>\n",
       "      <td>IT</td>\n",
       "      <td>[B08DYGN5W7, B09TW215N7, B08DJ18C85, B00IBDVTS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34687</th>\n",
       "      <td>IT</td>\n",
       "      <td>[B07ZH7HYDX, B07KXXCDS2, B00P2J6IP0, B08MNSMFP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34688</th>\n",
       "      <td>IT</td>\n",
       "      <td>[B09T5N86FW, B09RBZ3XDV, B09V52D3SQ, B0B245K5X...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34689</th>\n",
       "      <td>IT</td>\n",
       "      <td>[B08PCP2BB4, B08PCQQRB2, B08PCPF8G2, B09GYCC1N...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34690 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      locale                               next_item_prediction\n",
       "0         ES  [B074581R8Y, B074RZKWMD, B0745795KF, B07457KX2...\n",
       "1         ES  [B09J4T4JF5, B09NT33LZN, B09M8LNB61, B09NQKCQW...\n",
       "2         ES  [B0B461V1RB, B0B4643ZJN, B0B461KYQY, B0B38J377...\n",
       "3         ES  [B07R4VG9X3, B07R4WKSSV, B07QZ35DY6, B07QXZJK8...\n",
       "4         ES  [B09G97SLGS, B09G9DMQ7M, B09G99D95Q, B09G9LF91...\n",
       "...      ...                                                ...\n",
       "34685     IT  [B01F545TZQ, B01BBW9OAC, B09QH4W4LS, B01BBW9V3...\n",
       "34686     IT  [B08DYGN5W7, B09TW215N7, B08DJ18C85, B00IBDVTS...\n",
       "34687     IT  [B07ZH7HYDX, B07KXXCDS2, B00P2J6IP0, B08MNSMFP...\n",
       "34688     IT  [B09T5N86FW, B09RBZ3XDV, B09V52D3SQ, B0B245K5X...\n",
       "34689     IT  [B08PCP2BB4, B08PCQQRB2, B08PCPF8G2, B09GYCC1N...\n",
       "\n",
       "[34690 rows x 2 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "product_id2asin = pickle.load(open('../data/product_id2asin.pkl', 'rb'))\n",
    "locale = pd.read_pickle('../data/test_data2_p2.dataset').reset_index(drop=True)['locale']\n",
    "result = [[product_id2asin[x] for x in row[:100]] for row in recall1]\n",
    "result = pd.DataFrame({'locale':locale,'next_item_prediction':result})\n",
    "result.to_parquet( 'submission_locale_sum.parquet', engine='pyarrow')\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cudf",
   "language": "python",
   "name": "rapids-23.02"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
